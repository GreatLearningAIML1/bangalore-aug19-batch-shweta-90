{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "## Statistical NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Project Description\n",
    "\n",
    "Classification is probably the most popular task that you would deal with in real life.\n",
    "Text in the form of blogs, posts, articles, etc. is written every second. It is a challenge to predict the information about the writer without knowing about him/her.\n",
    "We are going to create a classifier that predicts multiple features of the author of a given text.\n",
    "We have designed it as a Multilabel classification problem.\n",
    "\n",
    "##Dataset\n",
    "\n",
    "Blog Authorship Corpus Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words - or approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a blogger id# and the blogger’s self-provided gender, age, industry, and astrological sign. (All are labeled for gender and age but for many, industry and/or sign is marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "8240 \"10s\" blogs (ages 13-17),\n",
    "8086 \"20s\" blogs(ages 23-27),\n",
    "2994 \"30s\" blogs (ages 33-47)\n",
    "For each age group, there is an equal number of male and female bloggers. Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions. Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label urllink. Link to dataset: https://www.kaggle.com/rtatman/blog-authorship-corpus/downloads/blog-authorship-corpus.zip/2at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach & Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>I had an interesting conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Somehow Coca-Cola has a way of su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>If anything, Korea is a country o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Take a read of this news article ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>I surf the English news sites a l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "5  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "6  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "7  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "8  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "9  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  \n",
       "5               I had an interesting conversation...  \n",
       "6               Somehow Coca-Cola has a way of su...  \n",
       "7               If anything, Korea is a country o...  \n",
       "8               Take a read of this news article ...  \n",
       "9               I surf the English news sites a l...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.Load the dataset\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report,f1_score, accuracy_score, recall_score, precision_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Read data \n",
    "corpus_df = pd.read_csv(\"blogtext.csv\")\n",
    "corpus_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail          '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df_sample = corpus_df[:3000]       #taking initial 3000 rows\n",
    "print(corpus_df_sample.shape)\n",
    "corpus_df_sample[\"text\"].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           These are the team members    Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering  me           urlLink mail          '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.Preprocess rows of the “text” column\n",
    "    # a. Remove unwanted characters\n",
    "corpus_df_sample['text'] = corpus_df_sample['text'].str.replace('[^A-Za-z]',' ')\n",
    "corpus_df_sample[\"text\"].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           these are the team members    drewes van der laag           urllink mail  ruiyu xie                     urllink mail  bryan aaldering  me           urllink mail          '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b. Convert text to lowercase\n",
    "corpus_df_sample['text'] = corpus_df_sample['text'].str.lower()\n",
    "corpus_df_sample[\"text\"].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'these are the team members    drewes van der laag           urllink mail  ruiyu xie                     urllink mail  bryan aaldering  me           urllink mail'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c. Remove unwanted spaces\n",
    "corpus_df_sample[\"text\"] = corpus_df_sample[\"text\"].str.strip()\n",
    "corpus_df_sample[\"text\"].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "corpus_df_sample[\"text\"] = corpus_df_sample[\"text\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d.Remove stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "def removestopwords(y):   # Function definition\n",
    " stopwordremoved = [w for w in y if w not in stop]\n",
    " return(\" \".join(stopwordremoved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text column size : 3000\n"
     ]
    }
   ],
   "source": [
    "text_column_size = corpus_df_sample[\"text\"].size\n",
    "print(\"text column size :\", text_column_size)\n",
    "\n",
    "# Initialize an empty list to hold the text after stop word removal\n",
    "cleaner_corpus_df_sample_text = []\n",
    "\n",
    "# Loop over each text\n",
    "for i in range( 0, text_column_size):\n",
    "    cleaner_corpus_df_sample_text.append(removestopwords(corpus_df_sample[\"text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'team members drewes van der laag urllink mail ruiyu xie urllink mail bryan aaldering urllink mail'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner_corpus_df_sample_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ah korean language looks difficult first figure read hanguel korea surprisingly easy learn alphabet characters seems easy vocabulary starts oh backwards us sentence structure yikes luckily many options us slow witted foreigners take language course could list urllink joongang article says lot resources urllink well guy motivation jeon ji hyun latest something actually star movies cfs hear means commercial feature positive saw latest movie sunday night hard describe name english version windstruck korean version yeochinso short ne yeojachingu rul sogayhamnida like introduce girlfriend surprisingly titles make sense like website korean english looks quite good actually urllink movie shown theatres subtitles special times info urllink list many theatres seoul click urllink urllink great reason learn korean already married went foreigners well local korean national course korean take picture put urllink movie hof bar update bud mine passed urllink link giordano ad apparently aired korea nothing xxx sensibilities sort'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Replace text column with cleaner_corpus_df_sample_text \n",
    "corpus_df_sample[\"text\"] = cleaner_corpus_df_sample_text\n",
    "corpus_df_sample[\"text\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4784: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "corpus_df_sample[\"text\"].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\malash01\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "# lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemm = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "    return(\" \".join(lemm)) \n",
    "\n",
    "corpus_df_sample[\"text\"] = corpus_df_sample.text.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'team member drewes van der laag urllink mail ruiyu xie urllink mail bryan aaldering urllink mail'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df_sample[\"text\"][1] # Lemmatized output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')\n",
      "(3000, 7)\n",
      "        id gender  age    topic sign         date  \\\n",
      "0  2059027   male   15  Student  Leo  14,May,2004   \n",
      "1  2059027   male   15  Student  Leo  13,May,2004   \n",
      "\n",
      "                                                text  \n",
      "0  info found page mb pdf file wait untill team l...  \n",
      "1  team member drewes van der laag urllink mail r...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>info found page mb pdf file wait untill team l...</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>team member drewes van der laag urllink mail r...</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>thanks yahoo toolbar capture url popups mean s...</td>\n",
       "      <td>male,33,InvestmentBanking,Aquarius</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  info found page mb pdf file wait untill team l...   \n",
       "1  team member drewes van der laag urllink mail r...   \n",
       "2  het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                    testing testing   \n",
       "4  thanks yahoo toolbar capture url popups mean s...   \n",
       "\n",
       "                               labels  \n",
       "0                 male,15,Student,Leo  \n",
       "1                 male,15,Student,Leo  \n",
       "2                 male,15,Student,Leo  \n",
       "3                 male,15,Student,Leo  \n",
       "4  male,33,InvestmentBanking,Aquarius  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. As we want to make this into a multi-label classification problem, \n",
    "# you are required to merge all the label columns together, \n",
    "# so that we have all the labels together for a particular sentence\n",
    "\n",
    "# a. Label columns to merge: “gender”, “age”, “topic”, “sign”\n",
    "print(corpus_df_sample.columns)\n",
    "print(corpus_df_sample.shape)\n",
    "print(corpus_df_sample.head(2))\n",
    "\n",
    "corpus_df_sample['age'] = corpus_df_sample['age'].astype(str)\n",
    "corpus_df_sample['labels'] = corpus_df_sample[['gender','age','topic','sign']].apply(lambda x: ','.join(x), axis = 1) \n",
    "corpus_df_sample_merged = corpus_df_sample.drop(labels = ['date','gender', 'age','topic','sign','id'], axis = 1)\n",
    "corpus_df_sample_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.After completing the previous step, \n",
    "# there should be only two columns in your data frame i.e. “text” and “labels”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df_sample_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2010,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Separate features and labels, and split the data into training and testing\n",
    "feature = corpus_df_sample_merged['text']\n",
    "corpus_df_sample_merged['labels'] = corpus_df_sample_merged['labels'].str.lower()\n",
    "labels = corpus_df_sample_merged['labels']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(feature,labels, test_size = 0.33, random_state = 143)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape & sample (2010, 16018)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x16018 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Vectorize the features\n",
    "    # a. Create a Bag of Words using count vectorizer: i. Use ngram_range=(1, 2); ii. Vectorize training and testing features\n",
    "    # b. Print the term-document matrix\n",
    "vectorizer = CountVectorizer(min_df = 2,ngram_range = (1,2),stop_words = \"english\")\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "print(\"X_train shape & sample\",X_train.shape)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'male': 36,\n",
       " '15': 1,\n",
       " 'student': 47,\n",
       " 'leo': 33,\n",
       " '33': 9,\n",
       " 'investmentbanking': 32,\n",
       " 'aquarius': 18,\n",
       " 'female': 28,\n",
       " '14': 0,\n",
       " 'indunk': 30,\n",
       " 'aries': 19,\n",
       " '25': 6,\n",
       " 'capricorn': 24,\n",
       " '17': 3,\n",
       " 'gemini': 29,\n",
       " '23': 4,\n",
       " 'non': 39,\n",
       " 'profit': 41,\n",
       " 'cancer': 23,\n",
       " 'banking': 21,\n",
       " '37': 12,\n",
       " 'sagittarius': 43,\n",
       " '26': 7,\n",
       " '24': 5,\n",
       " 'scorpio': 45,\n",
       " '27': 8,\n",
       " 'education': 26,\n",
       " '45': 16,\n",
       " 'engineering': 27,\n",
       " 'libra': 34,\n",
       " 'science': 44,\n",
       " '34': 10,\n",
       " '41': 14,\n",
       " 'communications': 25,\n",
       " 'media': 37,\n",
       " 'businessservices': 22,\n",
       " 'sports': 46,\n",
       " 'recreation': 42,\n",
       " 'virgo': 50,\n",
       " 'taurus': 48,\n",
       " 'arts': 20,\n",
       " 'pisces': 40,\n",
       " '44': 15,\n",
       " '16': 2,\n",
       " 'internet': 31,\n",
       " 'museums': 38,\n",
       " 'libraries': 35,\n",
       " 'accounting': 17,\n",
       " '39': 13,\n",
       " '35': 11,\n",
       " 'technology': 49}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Create a dictionary to get the count of every label\n",
    "# i.e. the key will be label name and value will be the total count of the label.\n",
    "vectorizer_labels = CountVectorizer(min_df = 1,ngram_range = (1,1),stop_words = \"english\")\n",
    "labels_vector = vectorizer_labels.fit_transform(labels)\n",
    "vectorizer_labels.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14', '15', '16', '17', '23', '24', '25', '26', '27', '33', '34', '35', '37', '39', '41', '44', '45', 'accounting', 'aquarius', 'aries', 'arts', 'banking', 'businessservices', 'cancer', 'capricorn', 'communications', 'education', 'engineering', 'female', 'gemini', 'indunk', 'internet', 'investmentbanking', 'leo', 'libra', 'libraries', 'male', 'media', 'museums', 'non', 'pisces', 'profit', 'recreation', 'sagittarius', 'science', 'scorpio', 'sports', 'student', 'taurus', 'technology', 'virgo']\n"
     ]
    }
   ],
   "source": [
    "#7. Convert your train and test labels using MultiLabelBinarizer\n",
    "label_classes = []  \n",
    "for key in vectorizer_labels.vocabulary_.keys():\n",
    "    label_classes.append(key)\n",
    "    \n",
    "print(sorted(label_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes = label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male', '33', 'investmentbanking', 'aquarius']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [[\"\".join(re.findall(\"\\w\",f)) for f in lst] for lst in [s.split(\",\") for s in labels]]\n",
    "labels[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=['male', '15', 'student', 'leo', '33',\n",
       "                             'investmentbanking', 'aquarius', 'female', '14',\n",
       "                             'indunk', 'aries', '25', 'capricorn', '17',\n",
       "                             'gemini', '23', 'non', 'profit', 'cancer',\n",
       "                             'banking', '37', 'sagittarius', '26', '24',\n",
       "                             'scorpio', '27', 'education', '45', 'engineering',\n",
       "                             'libra', ...],\n",
       "                    sparse_output=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_trans = mlb.fit(labels) # transforming entire set of lables\n",
    "labels_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male', '24', 'engineering', 'libra']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = [[\"\".join(re.findall(\"\\w\",f)) for f in lst] for lst in [s.split(\",\") for s in Y_train]]\n",
    "Y_train[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:951: UserWarning: unknown class(es) ['communicationsmedia', 'museumslibraries', 'nonprofit', 'sportsrecreation'] will be ignored\n",
      "  .format(sorted(unknown, key=str)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y_train_trans = mlb.transform(Y_train) # transforming Train lables using mlb which is trained on all possible unnique labels on entire data set\n",
    "Y_train_trans[30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2010, 51)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male', '35', 'technology', 'aries']\n",
      "[1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "Y_test = [[\"\".join(re.findall(\"\\w\",f)) for f in lst] for lst in [s.split(\",\") for s in Y_test]]\n",
    "Y_test_trans = mlb.transform(Y_test) # transforming test labels.\n",
    "print(Y_test[30])\n",
    "print(Y_test_trans[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male', '15', 'student', 'leo', '33', 'investmentbanking',\n",
       "       'aquarius', 'female', '14', 'indunk', 'aries', '25', 'capricorn',\n",
       "       '17', 'gemini', '23', 'non', 'profit', 'cancer', 'banking', '37',\n",
       "       'sagittarius', '26', '24', 'scorpio', '27', 'education', '45',\n",
       "       'engineering', 'libra', 'science', '34', '41', 'communications',\n",
       "       'media', 'businessservices', 'sports', 'recreation', 'virgo',\n",
       "       'taurus', 'arts', 'pisces', '44', '16', 'internet', 'museums',\n",
       "       'libraries', 'accounting', '39', '35', 'technology'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y_train_trans[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['male', '25', 'nonprofit', 'cancer']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. In this task, we suggest using the One-vs-Rest approach, which is implemented in OneVsRestClassifier class. \n",
    "# In this approach k classifiers (= number of tags) are trained. As a basic classifier, use LogisticRegression. \n",
    "# It is one of the simplest methods, but often it performs good enough in text classification tasks. \n",
    "# It might take some time because the number of classifiers to train is large.\n",
    "# a. Use a linear classifier of your choice, wrap it up in OneVsRestClassifier to train it on every label\n",
    "clf = LogisticRegression(solver = 'lbfgs')\n",
    "clf = OneVsRestClassifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 16 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 17 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 33 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 34 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 36 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 37 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 45 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label not 46 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Fit the classifier, make predictions and get the accuracy\n",
    "\n",
    "clf.fit(X_train,Y_train_trans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.972139303482587\n",
      "Test Accuracy:0.5686868686868687\n",
      "F1: 0.7584394023242943\n",
      "F1_macro: 0.2777544085541704\n",
      "Precision: 0.8270971635485818\n",
      "Precision_macro: 0.42504160995159523\n",
      "Recall: 0.7003065917220235\n",
      "Recall_macro: 0.2290073113591835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print the following  \n",
    "# i. Accuracy score\n",
    "# ii. F1 score  \n",
    "# iii. Average precision score\n",
    "# iv. Average recall score \n",
    "# v. Tip: Make sure you are familiar with all of them. \n",
    "    #   How would you expect the things to work for the multi-label scenario? \n",
    "    #   Read about micro/macro/weighted averaging\n",
    "\n",
    "print(\"Train Accuracy:\",clf.score(X_train,Y_train_trans))\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\" + str(accuracy_score(Y_test_trans, Y_pred)))\n",
    "print(\"F1: \" + str(f1_score(Y_test_trans, Y_pred, average='micro')))\n",
    "print(\"F1_macro: \" + str(f1_score(Y_test_trans, Y_pred, average='macro')))\n",
    "print(\"Precision: \" + str(precision_score(Y_test_trans, Y_pred, average='micro')))\n",
    "print(\"Precision_macro: \" + str(precision_score(Y_test_trans, Y_pred, average='macro')))\n",
    "print(\"Recall: \" + str(recall_score(Y_test_trans, Y_pred, average='micro')))\n",
    "print(\"Recall_macro: \" + str(recall_score(Y_test_trans, Y_pred, average='macro')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Print true label and predicted label for any five examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_inv = mlb.inverse_transform(Y_pred)   # inverse transforming predited label data\n",
    "Y_test_trans_inv =  mlb.inverse_transform(Y_test_trans) # inverse transforming original test label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1 - predicted : ('male', 'aries', '35', 'technology')\n",
      "Example 1 - Actual : ('aquarius', 'female', '27', 'education')\n",
      "Example 1 - Actual_before mlb transformation : ['female', '27', 'education', 'aquarius']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 1 - predicted :\",Y_pred_inv[0])\n",
    "print(\"Example 1 - Actual :\",Y_test_trans_inv[0])\n",
    "print(\"Example 1 - Actual_before mlb transformation :\",Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2 - predicted : ('male', 'aries', '35', 'technology')\n",
      "Example 2 - Actual : ('male', 'aries', '35', 'technology')\n",
      "Example 2 - Actual_before mlb transformation : ['male', '35', 'technology', 'aries']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 2 - predicted :\",Y_pred_inv[1])\n",
    "print(\"Example 2 - Actual :\",Y_test_trans_inv[1])\n",
    "print(\"Example 2 - Actual_before mlb transformation :\",Y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3 - predicted : ('male', 'aries', '35', 'technology')\n",
      "Example 3 - Actual : ('male', 'aries', '35', 'technology')\n",
      "Example 3 - Actual_before mlb transformation : ['male', '35', 'technology', 'aries']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 3 - predicted :\",Y_pred_inv[13])\n",
    "print(\"Example 3 - Actual :\",Y_test_trans_inv[13])\n",
    "print(\"Example 3 - Actual_before mlb transformation :\",Y_test[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 4 - predicted : ('male', '15', 'student', 'aries', '35', 'technology')\n",
      "Example 4 - Actual : ('15', 'student', 'aquarius', 'female')\n",
      "Example 4 - Actual_before mlb transformation : ['female', '15', 'student', 'aquarius']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 4 - predicted :\",Y_pred_inv[139])\n",
    "print(\"Example 4 - Actual :\",Y_test_trans_inv[139])\n",
    "print(\"Example 4 - Actual_before mlb transformation :\",Y_test[139])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 5 - predicted : ('male', 'aries', '35', 'technology')\n",
      "Example 5 - Actual : ('male', 'indunk', '23', 'sagittarius')\n",
      "Example 5 - Actual_before mlb transformation : ['male', '23', 'indunk', 'sagittarius']\n"
     ]
    }
   ],
   "source": [
    "print(\"Example 5 - predicted :\",Y_pred_inv[110])\n",
    "print(\"Example 5 - Actual :\",Y_test_trans_inv[110])\n",
    "print(\"Example 5 - Actual_before mlb transformation :\",Y_test[110])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
